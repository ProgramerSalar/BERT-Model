{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import collections\n",
    "import json\n",
    "import math \n",
    "import re \n",
    "import numpy as np \n",
    "import six \n",
    "import tensorflow as tf\n",
    "import copy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertConfig(object):\n",
    "\n",
    "    \"\"\"Configuration for `BertModel`. \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                hidden_size = 768,\n",
    "                 num_hidden_layers = 12,\n",
    "                 num_attention_heads = 12,\n",
    "                 intermediate_size = 3072,             # hidden layers \n",
    "                 hidden_act=\"gelu\",\n",
    "                 hidden_dropout_prob = 0.1,\n",
    "                 attention_probs_dropout_prob = 0.1,\n",
    "                 max_position_embeddings = 512,\n",
    "                 type_vocab_size = 16,\n",
    "                 initializer_range = 0.02\n",
    "\n",
    "\n",
    "                 ) -> None:\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        Constructs BertConfig.\n",
    "\n",
    "        Args:\n",
    "            vocab_size: Vocabulary size of `input_ids` in `BertModel`.\n",
    "            hidden_size: Size of the encoder and the pooler layer.\n",
    "            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n",
    "            num_attention_heads: Number of attention heads for each attention layer in \n",
    "                the Transformer encoder.\n",
    "\n",
    "            intermediate_size: the size of the \"intermediate\" (i.e, feed-forward)\n",
    "                layer in the Transformer encoder.\n",
    "\n",
    "            hidden_act: The non-linear activation function (function or string) in the \n",
    "                encoder and pooler.\n",
    "\n",
    "\n",
    "            hidden_dropout_prob: The dropout probability for all fully connected \n",
    "                layers in the embeddings, encoder and pooler.\n",
    "\n",
    "            attention_probs_dropout_prob: The dropout ratio for the attention probabilities.\n",
    "\n",
    "            max_position_embeddings: The maximum sequence length that this model might \n",
    "                ever be used with. Typically set this to something large just in case \n",
    "                (e.g, 512 or 1024 or 2048).\n",
    "\n",
    "            type_vocab_size: The vocabulary size of the `token_type_ids` passed into \n",
    "                `BertModel`.\n",
    "\n",
    "            initializer_range: The stdev of the truncated_normal_initializer for \n",
    "                initializing all weight matrices.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.intermediate_size = intermediate_size\n",
    "        self.hidden_act = hidden_act\n",
    "        self.hidden_dropout_prob = hidden_dropout_prob\n",
    "        self.attention_probs_dropout_prob = attention_probs_dropout_prob\n",
    "        self.max_position_embeddings = max_position_embeddings\n",
    "        self.type_vocab_size = type_vocab_size\n",
    "        self.initializer_range = initializer_range\n",
    "\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, json_object):\n",
    "        \"\"\"Constructs a `BertConfig` from a Python dictionary of parameters. \"\"\"\n",
    "        config = BertConfig(vocab_size=None)\n",
    "        for (key, value) in six.iteritems(json_object):\n",
    "            # print(\"key\", key)\n",
    "            # print(\"value\", value)\n",
    "\n",
    "            config.__dict__[key] = value\n",
    "            # print(\"values\", value)\n",
    "\n",
    "        # print(\"config\", config)\n",
    "        return config\n",
    "    \n",
    "\n",
    "    @classmethod\n",
    "    def from_json_file(cls, json_file):\n",
    "        \"\"\"Constructs a `BertConfig` from a json file of parameters. \"\"\"\n",
    "        with tf.io.gfile.GFile(json_file, \"r\") as reader:\n",
    "            text = reader.read()\n",
    "            print(text)\n",
    "        return cls.from_dict(json.loads(text))\n",
    "    \n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"Serializes this instance to a Python dictionary.\"\"\"\n",
    "        output = copy.deepcopy(self.__dict__)\n",
    "        print(output)\n",
    "\n",
    "\n",
    "    def to_json_string(self):\n",
    "        \"\"\"Serializes this instance to a JSON string.\"\"\"\n",
    "        return json.dumps(self.to_dict(), indent=2, sort_keys=True) + \"\\n\"\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_dict = {\n",
    "#     \"vocab_size\": 30522,\n",
    "#     \"hidden_size\": 768,\n",
    "#     \"num_hidden_layers\": 12,\n",
    "#     \"num_attention_heads\": 12,\n",
    "#     \"intermediate_size\": 3072,\n",
    "#     \"hidden_act\": \"gelu\",\n",
    "#     \"hidden_dropout_prob\": 0.1,\n",
    "#     \"attention_probs_dropout_prob\": 0.1,\n",
    "#     \"max_position_embeddings\": 512,\n",
    "#     \"type_vocab_size\": 16,\n",
    "#     \"initializer_range\": 0.02\n",
    "# }\n",
    "\n",
    "\n",
    "## access the data in dictionary ##\n",
    "# BertConfig.from_dict(json_object=config_dict)\n",
    "\n",
    "## access the data in file ##\n",
    "# BertConfig.from_json_file(json_file=\"config.json\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "config = BertConfig(\n",
    "    vocab_size=30522,\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    hidden_act=\"gelu\",\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    max_position_embeddings=512,\n",
    "    type_vocab_size=16,\n",
    "    initializer_range=0.02\n",
    ")\n",
    "\n",
    "## copy the data and convert to dictionary ## \n",
    "# config.to_dict()\n",
    "\n",
    "## dums the data  ##  \n",
    "# config.to_json_string()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assert Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: True}\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.assert_rank(tensor, expected_rank, name=None)>"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def assert_rank(tensor, expected_rank, name=None):\n",
    "\n",
    "    \"\"\"Raises an exception if the tensor rank is not of the expected rank.\n",
    "    \n",
    "    Args:\n",
    "        tensor: A tf.Tensor to check the rank of.\n",
    "        expected_rank: Python integer or list of intergers, expected rank.\n",
    "        name: Optional name of the tensor for the error message.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the expected shape doesn't mastch the actual shape.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    if name is None:\n",
    "        name = \"tensor\"\n",
    "\n",
    "    expected_rank_dict = {}\n",
    "    if isinstance(expected_rank, six.integer_types):\n",
    "        expected_rank_dict[expected_rank] = True \n",
    "        print(expected_rank_dict)\n",
    "\n",
    "    else:\n",
    "        for x in expected_rank:\n",
    "            print(x)\n",
    "            expected_rank_dict[x] = True\n",
    "            print(expected_rank_dict)\n",
    "\n",
    "\n",
    "    actual_rank = tensor.shape.ndims\n",
    "    print(actual_rank) \n",
    "\n",
    "    if actual_rank not in expected_rank_dict:\n",
    "        # print(\"not found\")\n",
    "        scope_name = tf.compat.v1.get_variable_scope().name\n",
    "        print(\"sco\", scope_name)\n",
    "        raise ValueError(\n",
    "            \"For the tensor `%s` in scope `%s`, the actual rank \"\n",
    "            \"`%d` (shape = %s) in not equal to the expected rank `%s`\" \n",
    "            % (name, scope_name, actual_rank, str(tensor.shape), str(expected_rank))\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Example usage \n",
    "tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "expected_rank = 2\n",
    "\n",
    "assert_rank(tensor=tensor,\n",
    "            expected_rank=expected_rank)\n",
    "assert_rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'20': True}\n"
     ]
    }
   ],
   "source": [
    "import six \n",
    "\n",
    "# check if a number is an instance of int \n",
    "x = \"20\"\n",
    "creat_a_list = {}\n",
    "# print(isinstance(x, int))\n",
    "isinstance(x, six.integer_types)\n",
    "\n",
    "creat_a_list[x] = True\n",
    "print(creat_a_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Shape in List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: True}\n",
      "1\n",
      "shape [5]\n",
      "Index: 0, dimension: 5 \n",
      "non static index []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.get_shape_list(tensor, expected_rank=None, name=None)>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def get_shape_list(tensor, expected_rank=None, name=None):\n",
    "\n",
    "    \"\"\"Returns a list of the shape of tensor, preferring static dimensions.\n",
    "    \n",
    "    Args:\n",
    "        tensor: A tf.Tensor object to find the shape of.\n",
    "        expected_rank: (optional) int. The expected rank of `tensor`. if this is \n",
    "            specified and the `tensor` has a different rank, and exception will be thrown.\n",
    "\n",
    "        name: Optional name of the tensor for the error message.\n",
    "    \n",
    "    Returns:\n",
    "        A list of dimension of the shape of tensor. All static diemsnions will \n",
    "        be returned as python integers, and dynamic dimensions will be returned \n",
    "        as tf.Tensor scalars.\n",
    "    \"\"\"\n",
    "\n",
    "    if name is None:\n",
    "        name = \"tensor\"\n",
    "\n",
    "    if expected_rank is not None:\n",
    "        assert_rank(tensor=tensor,\n",
    "                    expected_rank=expected_rank,\n",
    "                    name=name)\n",
    "        \n",
    "    shape = tensor.shape.as_list()\n",
    "    print(\"shape\", shape)\n",
    "\n",
    "    non_static_indexes = []\n",
    "    for (index, dim) in enumerate(shape):\n",
    "        print(f\"Index: {index}, dimension: {dim} \")\n",
    "\n",
    "        if dim is None:\n",
    "            non_static_indexes.append(index)\n",
    "\n",
    "        print(\"non static index\", non_static_indexes)\n",
    "\n",
    "    if not non_static_indexes:\n",
    "        return shape \n",
    "    # print(\"shapes\", shape)\n",
    "\n",
    "    dyn_shape = tf.shape(tensor)\n",
    "    print(\"dyn shape\", dyn_shape)\n",
    "\n",
    "    for index in non_static_indexes:\n",
    "        print(\"index\", index)\n",
    "        shape[index] = dyn_shape[index]\n",
    "    return shape\n",
    "    # print(\"shape\", shape)\n",
    "\n",
    "          \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tensor = tf.constant([1, 2, 3, 4, 5])\n",
    "expected_rank = 1\n",
    "\n",
    "get_shape_list(tensor=tensor,\n",
    "               expected_rank=expected_rank,\n",
    "               )\n",
    "\n",
    "get_shape_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 0, Character: H\n",
      "Index: 1, Character: e\n",
      "Index: 2, Character: l\n",
      "Index: 3, Character: l\n",
      "Index: 4, Character: o\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello\"\n",
    "\n",
    "# Use enumerate to loop over the string with an index \n",
    "for index, char in enumerate(text):\n",
    "    print(f\"Index: {index}, Character: {char}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.ops.init_ops.TruncatedNormal at 0x28b4f6bb0b0>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_initializer(initializer_range=0.02):\n",
    "    \"\"\"Creates a `truncated_normal_initializer` with the given range. \"\"\"\n",
    "    return tf.compat.v1.truncated_normal_initializer(stddev=initializer_range)\n",
    "\n",
    "\n",
    "create_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Table <tf.Variable 'word_embeddings:0' shape=(10, 8) dtype=float32, numpy=\n",
      "array([[-0.0047775 , -0.00056025,  0.00322218, -0.00152839,  0.03057186,\n",
      "         0.02056019, -0.03070413, -0.03836283],\n",
      "       [ 0.02806117,  0.02019441,  0.03813596, -0.02910769, -0.03083536,\n",
      "        -0.00305579, -0.00486355, -0.02026936],\n",
      "       [-0.02413152,  0.0214796 , -0.00069809, -0.02755495,  0.00177614,\n",
      "        -0.01034719, -0.00502856,  0.03347372],\n",
      "       [ 0.01538588,  0.00837055,  0.00117349, -0.03510724, -0.0135174 ,\n",
      "         0.01310523, -0.02054141, -0.02728004],\n",
      "       [ 0.01124805, -0.00391154, -0.00986872,  0.01353862, -0.00326916,\n",
      "        -0.01125768,  0.00669234, -0.03418828],\n",
      "       [ 0.01253894,  0.02574071, -0.01751015, -0.01008733, -0.00796913,\n",
      "        -0.0225878 , -0.01567531,  0.00335707],\n",
      "       [ 0.00504496,  0.01411746, -0.02582736,  0.008988  ,  0.01533897,\n",
      "         0.01092492,  0.01314643, -0.00613218],\n",
      "       [-0.00169873, -0.03128862,  0.02010647, -0.00709424, -0.00822985,\n",
      "         0.02054337,  0.00389071, -0.00348142],\n",
      "       [ 0.03602291,  0.01046078,  0.01306725, -0.0182344 ,  0.0254641 ,\n",
      "         0.00118984,  0.00329561, -0.00411679],\n",
      "       [-0.02909477, -0.00356589,  0.01527544,  0.02885145,  0.00717083,\n",
      "         0.00616482,  0.00046857,  0.02432154]], dtype=float32)>\n",
      "Gather output tf.Tensor(\n",
      "[[ 0.02806117  0.02019441  0.03813596 -0.02910769 -0.03083536 -0.00305579\n",
      "  -0.00486355 -0.02026936]\n",
      " [-0.02413152  0.0214796  -0.00069809 -0.02755495  0.00177614 -0.01034719\n",
      "  -0.00502856  0.03347372]\n",
      " [ 0.01538588  0.00837055  0.00117349 -0.03510724 -0.0135174   0.01310523\n",
      "  -0.02054141 -0.02728004]\n",
      " [ 0.01124805 -0.00391154 -0.00986872  0.01353862 -0.00326916 -0.01125768\n",
      "   0.00669234 -0.03418828]\n",
      " [ 0.01253894  0.02574071 -0.01751015 -0.01008733 -0.00796913 -0.0225878\n",
      "  -0.01567531  0.00335707]\n",
      " [ 0.00504496  0.01411746 -0.02582736  0.008988    0.01533897  0.01092492\n",
      "   0.01314643 -0.00613218]], shape=(6, 8), dtype=float32)\n",
      "shape [2, 3, 1]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n",
      "Index: 2, dimension: 1 \n",
      "non static index []\n",
      "Output: (tf.Tensor(\n",
      "[[[ 0.02806117  0.02019441  0.03813596 -0.02910769 -0.03083536\n",
      "   -0.00305579 -0.00486355 -0.02026936]\n",
      "  [-0.02413152  0.0214796  -0.00069809 -0.02755495  0.00177614\n",
      "   -0.01034719 -0.00502856  0.03347372]\n",
      "  [ 0.01538588  0.00837055  0.00117349 -0.03510724 -0.0135174\n",
      "    0.01310523 -0.02054141 -0.02728004]]\n",
      "\n",
      " [[ 0.01124805 -0.00391154 -0.00986872  0.01353862 -0.00326916\n",
      "   -0.01125768  0.00669234 -0.03418828]\n",
      "  [ 0.01253894  0.02574071 -0.01751015 -0.01008733 -0.00796913\n",
      "   -0.0225878  -0.01567531  0.00335707]\n",
      "  [ 0.00504496  0.01411746 -0.02582736  0.008988    0.01533897\n",
      "    0.01092492  0.01314643 -0.00613218]]], shape=(2, 3, 8), dtype=float32)) Embedding Table: (<tf.Variable 'word_embeddings:0' shape=(10, 8) dtype=float32, numpy=\n",
      "array([[-0.0047775 , -0.00056025,  0.00322218, -0.00152839,  0.03057186,\n",
      "         0.02056019, -0.03070413, -0.03836283],\n",
      "       [ 0.02806117,  0.02019441,  0.03813596, -0.02910769, -0.03083536,\n",
      "        -0.00305579, -0.00486355, -0.02026936],\n",
      "       [-0.02413152,  0.0214796 , -0.00069809, -0.02755495,  0.00177614,\n",
      "        -0.01034719, -0.00502856,  0.03347372],\n",
      "       [ 0.01538588,  0.00837055,  0.00117349, -0.03510724, -0.0135174 ,\n",
      "         0.01310523, -0.02054141, -0.02728004],\n",
      "       [ 0.01124805, -0.00391154, -0.00986872,  0.01353862, -0.00326916,\n",
      "        -0.01125768,  0.00669234, -0.03418828],\n",
      "       [ 0.01253894,  0.02574071, -0.01751015, -0.01008733, -0.00796913,\n",
      "        -0.0225878 , -0.01567531,  0.00335707],\n",
      "       [ 0.00504496,  0.01411746, -0.02582736,  0.008988  ,  0.01533897,\n",
      "         0.01092492,  0.01314643, -0.00613218],\n",
      "       [-0.00169873, -0.03128862,  0.02010647, -0.00709424, -0.00822985,\n",
      "         0.02054337,  0.00389071, -0.00348142],\n",
      "       [ 0.03602291,  0.01046078,  0.01306725, -0.0182344 ,  0.0254641 ,\n",
      "         0.00118984,  0.00329561, -0.00411679],\n",
      "       [-0.02909477, -0.00356589,  0.01527544,  0.02885145,  0.00717083,\n",
      "         0.00616482,  0.00046857,  0.02432154]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "def embedding_lookup(input_ids, \n",
    "                     vocab_size, \n",
    "                     embedding_size=128,\n",
    "                     initializer_range = 0.02,\n",
    "                     word_embedding_name = \"word_embeddings\",\n",
    "                     use_one_hot_embeddings=False\n",
    "                     ):\n",
    "    \n",
    "\n",
    "    \"\"\"Looks up words embeddings for id tensor.\n",
    "    \n",
    "    Args:\n",
    "        input_ids: int32 Tensor of shape [batch_size, seq_length] containing word \n",
    "            ids.\n",
    "        vocab_size: int. Size of the embedding vocabulary.\n",
    "        embedding_size: int. Width of the word embeddings.\n",
    "        word_embedding_name: string. Name of the embedding table. \n",
    "        use_one_hot_embeddings: bool. If True, use one-hot method for word \n",
    "            embeddings. If False, use `tf.gather()`.\n",
    "\n",
    "\n",
    "    Returns:\n",
    "        float Tensor of shape [batch_size, seq_length, embedding_size].\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # This function assumes that the input is of shape [batch_size, seq_length, num_inputs]\n",
    "    # if the input is a 2D tensor of shape [batch_size, seq_length], we reshape to [batch_size, seq_length, 1]\n",
    "\n",
    "    if input_ids.shape.ndims == 2:\n",
    "        # print(\"shape is equal\")\n",
    "        input_ids = tf.expand_dims(input=input_ids,\n",
    "                                   axis=[-1])\n",
    "        # print(\"input_ids\", input_ids)\n",
    "\n",
    "        embedding_table = tf.compat.v1.get_variable(\n",
    "            name=word_embedding_name,\n",
    "            shape = [vocab_size, embedding_size],\n",
    "            initializer = create_initializer(initializer_range=initializer_range)\n",
    "        )\n",
    "        print(\"Embedding Table %s\" % (embedding_table))\n",
    "\n",
    "        flat_input_ids = tf.reshape(input_ids, [-1])   # convert two dimension to one dimension \n",
    "        if use_one_hot_embeddings:\n",
    "            one_hot_input_ids = tf.one_hot(flat_input_ids, depth=vocab_size)\n",
    "            # print(\"one hot input\", one_hot_input_ids)\n",
    "            output = tf.matmul(one_hot_input_ids, embedding_table)\n",
    "            print(\"matrix multiplication output\", output)\n",
    "\n",
    "        else:\n",
    "            output = tf.gather(embedding_table, indices=flat_input_ids)\n",
    "            print(\"Gather output\", output)\n",
    "\n",
    "        input_shape = get_shape_list(input_ids)\n",
    "\n",
    "        output = tf.reshape(tensor=output,\n",
    "                            shape=input_shape[0: -1] + [input_shape[-1] * embedding_size]\n",
    "                            )\n",
    "        \n",
    "        print(\"Output: (%s) Embedding Table: (%s)\" % (output, embedding_table))\n",
    "        return (output, embedding_table)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "input_ids = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "vocab_size = 10\n",
    "embedding_size = 8\n",
    "\n",
    "embeddings = embedding_lookup(input_ids, vocab_size, embedding_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONE Dimension are tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32) \n",
      "Two dimension tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n",
      "three dimension tf.Tensor(\n",
      "[[[1 2 3]]\n",
      "\n",
      " [[4 5 6]]], shape=(2, 1, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.constant([[1, 2, 3,], [4, 5, 6]])\n",
    "a = tf.reshape(tensor=tensor,\n",
    "           shape=[-1])\n",
    "print(\"ONE Dimension are %s \" %a)\n",
    "\n",
    "two_dim = tf.reshape(tensor,\n",
    "                     shape=[2, 3])\n",
    "print(\"Two dimension\", two_dim)\n",
    "\n",
    "three_dim = tf.reshape(tensor, \n",
    "                       shape=[2, 1, 3])\n",
    "print(\"three dimension\", three_dim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[19 22]\n",
      " [43 50]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([[1, 2], [3, 4]])\n",
    "B = tf.constant([[5, 6], [7, 8]])\n",
    "\n",
    "c = tf.matmul(A, B)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathered data: [1 4 5]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a TensorFlow constant tensor\n",
    "data = tf.constant([1, 2, 3, 4, 5, 6])\n",
    "\n",
    "# Define the indices to gather\n",
    "indices = tf.constant([0, 3, 4])\n",
    "\n",
    "# Use tf.gather to gather the elements at the specified indices\n",
    "gathered_data = tf.gather(data, indices)\n",
    "\n",
    "print(\"Gathered data:\", gathered_data.numpy())    # [1, 2, 5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: True}\n",
      "3\n",
      "shape [2, 10, 128]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 10 \n",
      "non static index []\n",
      "Index: 2, dimension: 128 \n",
      "non static index []\n"
     ]
    }
   ],
   "source": [
    "def embedding_postprocessor(input_tensor,\n",
    "                            use_token_type=False,\n",
    "                            token_type_ids=None,\n",
    "                            token_type_vocab_size=16,\n",
    "                            token_type_embedding_name=\"token_type_embeddings\",\n",
    "                            use_positional_embeddings=True,\n",
    "                            position_embedding_name=\"position_embeddings\",\n",
    "                            initializer_range = 0.02,\n",
    "                            max_position_embeddings=512,\n",
    "                            dropout_prob = 0.1\n",
    "                        \n",
    "                            ):\n",
    "    \n",
    "\n",
    "    \"\"\"Performs various post-processing on a word embedding tensor.\n",
    "    \n",
    "    Args:\n",
    "        input_tensor: float. Tensor of shape [batch_size, seq_length, embedding_size],\n",
    "        use_token_type: bool. Whether to add embeddings for `token_type_ids`.\n",
    "        token_type_ids: (optional) int32 Tensor of shape [batch_size, seq_length].\n",
    "            Must be specified if  `use_token_type` is True.\n",
    "\n",
    "        token_type_vocab_size: int. The vocabulary size of `token_type_ids`.\n",
    "        token_type_embedding_name: string. The name of the embedding table \n",
    "            variable for token type ids.\n",
    "\n",
    "        use_position_embeddings: bool. Whether to add position embeddings for the \n",
    "            position of each token in the sequence.\n",
    "\n",
    "        position_embedding_name: string. The name of the embedding table variable \n",
    "            for positional embeddings.\n",
    "\n",
    "        initializer_range: float. Range of the weight initialization.\n",
    "        max_position_embeddings: int. Maximum sequence length that might ever be \n",
    "            used width this model. This can be longer than the sequence length of \n",
    "            input_tensor, but coannot be shorter.\n",
    "\n",
    "        dropout_prob: float. Dropout probability applied to the final output tensor.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "        float tensor with same shape as `input_tensor`.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: One of the tensor shapes or input values is invalid.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    input_shape = get_shape_list(tensor=input_tensor,\n",
    "                                 expected_rank=3)\n",
    "    \n",
    "    batch_size = input_shape[0]\n",
    "    seq_length = input_shape[1]\n",
    "    width = input_shape[2]\n",
    "\n",
    "    output = input_tensor\n",
    "\n",
    "    if use_token_type:\n",
    "        if token_type_ids is None:\n",
    "            raise ValueError(\"`token_type_ids` must be specified if\"\n",
    "                             \"`use_token_type is True.\"\n",
    "                             )\n",
    "        \n",
    "\n",
    "        token_type_table = tf.compat.v1.get_variable(\n",
    "            name=token_type_embedding_name,\n",
    "            shape=[token_type_vocab_size, width],\n",
    "            initializer=create_initializer(initializer_range)\n",
    "        )\n",
    "        # print(\"token type table\", token_type_table)\n",
    "\n",
    "        # This vocab will be small so we always do one-hot here, since it is always \n",
    "        # faster for a small vocabulary.\n",
    "\n",
    "        flat_token_type_ids = tf.reshape(token_type_ids, [-1])\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Example usage \n",
    "input_tensor = tf.random.uniform(shape=[2, 10, 128], minval=0, maxval=1)\n",
    "token_type_ids = tf.constant([[0, 0, 0, 1, 1, 1, 0, 0, 0, 0], [1, 1, 1, 0, 0, 0, 1, 1, 1, 1]])\n",
    "\n",
    "processed_embeddings = embedding_postprocessor(input_tensor, \n",
    "                                               use_token_type=True, \n",
    "                                               token_type_ids=token_type_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [2, 3]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n",
      "{2: True}\n",
      "2\n",
      "shape [2, 3]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=\n",
       "array([[[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]],\n",
       "\n",
       "       [[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_attention_mask_from_input_mask(from_tensor, to_mask):\n",
    "  \"\"\"Create 3D attention mask from a 2D tensor mask.\n",
    "\n",
    "  Args:\n",
    "    from_tensor: 2D or 3D Tensor of shape [batch_size, from_seq_length, ...].\n",
    "    to_mask: int32 Tensor of shape [batch_size, to_seq_length].\n",
    "\n",
    "  Returns:\n",
    "    float Tensor of shape [batch_size, from_seq_length, to_seq_length].\n",
    "  \"\"\"\n",
    "  from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n",
    "  batch_size = from_shape[0]\n",
    "  from_seq_length = from_shape[1]\n",
    "\n",
    "  to_shape = get_shape_list(to_mask, expected_rank=2)\n",
    "  to_seq_length = to_shape[1]\n",
    "\n",
    "  to_mask = tf.cast(\n",
    "      tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n",
    "\n",
    "  # We don't assume that `from_tensor` is a mask (although it could be). We\n",
    "  # don't actually care if we attend *from* padding tokens (only *to* padding)\n",
    "  # tokens so we create a tensor of all ones.\n",
    "  #\n",
    "  # `broadcast_ones` = [batch_size, from_seq_length, 1]\n",
    "  broadcast_ones = tf.ones(\n",
    "      shape=[batch_size, from_seq_length, 1], dtype=tf.float32)\n",
    "\n",
    "  # Here we broadcast along two dimensions to create the mask.\n",
    "  mask = broadcast_ones * to_mask\n",
    "\n",
    "  return mask\n",
    "\n",
    "\n",
    "from_tensor = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "to_mask = tf.constant([[1, 1, 1], [0, 0, 0]])\n",
    "\n",
    "create_attention_mask_from_input_mask(from_tensor=from_tensor,\n",
    "                                      to_mask=to_mask)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gelu(x):\n",
    "  \"\"\"Gaussian Error Linear Unit.\n",
    "\n",
    "  This is a smoother version of the RELU.\n",
    "  Original paper: https://arxiv.org/abs/1606.08415\n",
    "  Args:\n",
    "    x: float Tensor to perform activation.\n",
    "\n",
    "  Returns:\n",
    "    `x` with the GELU activation applied.\n",
    "  \"\"\"\n",
    "  cdf = 0.5 * (1.0 + tf.tanh(\n",
    "      (np.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3)))))\n",
    "  return x * cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_to_matrix(input_tensor):\n",
    "  \"\"\"Reshapes a >= rank 2 tensor to a rank 2 tensor (i.e., a matrix).\"\"\"\n",
    "  ndims = input_tensor.shape.ndims\n",
    "  if ndims < 2:\n",
    "    raise ValueError(\"Input tensor must have at least rank 2. Shape = %s\" %\n",
    "                     (input_tensor.shape))\n",
    "  if ndims == 2:\n",
    "    return input_tensor\n",
    "\n",
    "  width = input_tensor.shape[-1]\n",
    "  output_tensor = tf.reshape(input_tensor, [-1, width])\n",
    "  return output_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(input_tensor, dropout_prob):\n",
    "  \"\"\"Perform dropout.\n",
    "\n",
    "  Args:\n",
    "    input_tensor: float Tensor.\n",
    "    dropout_prob: Python float. The probability of dropping out a value (NOT of\n",
    "      *keeping* a dimension as in `tf.nn.dropout`).\n",
    "\n",
    "  Returns:\n",
    "    A version of `input_tensor` with dropout applied.\n",
    "  \"\"\"\n",
    "  if dropout_prob is None or dropout_prob == 0.0:\n",
    "    return input_tensor\n",
    "\n",
    "  output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n",
    "  return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_norm(input_tensor, name=None):\n",
    "    \"\"\"Run layer normalization on the last dimension of the tensor.\"\"\"\n",
    "    return tf.keras.layers.LayerNormalization(axis=-1, name=name)(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_from_matrix(output_tensor, orig_shape_list):\n",
    "  \"\"\"Reshapes a rank 2 tensor back to its original rank >= 2 tensor.\"\"\"\n",
    "  if len(orig_shape_list) == 2:\n",
    "    return output_tensor\n",
    "\n",
    "  output_shape = get_shape_list(output_tensor)\n",
    "\n",
    "  orig_dims = orig_shape_list[0:-1]\n",
    "  width = output_shape[-1]\n",
    "\n",
    "  return tf.reshape(output_tensor, orig_dims + [width])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_layer(from_tensor,\n",
    "                    to_tensor,\n",
    "                    attention_mask=None,\n",
    "                    num_attention_heads=1,\n",
    "                    size_per_head=512,\n",
    "                    query_act=None,\n",
    "                    key_act=None,\n",
    "                    value_act=None,\n",
    "                    attention_probs_dropout_prob=0.0,\n",
    "                    initializer_range=0.02,\n",
    "                    do_return_2d_tensor=False,\n",
    "                    batch_size=None,\n",
    "                    from_seq_length=None,\n",
    "                    to_seq_length=None):\n",
    "  \"\"\"Performs multi-headed attention from `from_tensor` to `to_tensor`.\n",
    "\n",
    "  This is an implementation of multi-headed attention based on \"Attention\n",
    "  is all you Need\". If `from_tensor` and `to_tensor` are the same, then\n",
    "  this is self-attention. Each timestep in `from_tensor` attends to the\n",
    "  corresponding sequence in `to_tensor`, and returns a fixed-with vector.\n",
    "\n",
    "  This function first projects `from_tensor` into a \"query\" tensor and\n",
    "  `to_tensor` into \"key\" and \"value\" tensors. These are (effectively) a list\n",
    "  of tensors of length `num_attention_heads`, where each tensor is of shape\n",
    "  [batch_size, seq_length, size_per_head].\n",
    "\n",
    "  Then, the query and key tensors are dot-producted and scaled. These are\n",
    "  softmaxed to obtain attention probabilities. The value tensors are then\n",
    "  interpolated by these probabilities, then concatenated back to a single\n",
    "  tensor and returned.\n",
    "\n",
    "  In practice, the multi-headed attention are done with transposes and\n",
    "  reshapes rather than actual separate tensors.\n",
    "\n",
    "  Args:\n",
    "    from_tensor: float Tensor of shape [batch_size, from_seq_length,\n",
    "      from_width].\n",
    "    to_tensor: float Tensor of shape [batch_size, to_seq_length, to_width].\n",
    "    attention_mask: (optional) int32 Tensor of shape [batch_size,\n",
    "      from_seq_length, to_seq_length]. The values should be 1 or 0. The\n",
    "      attention scores will effectively be set to -infinity for any positions in\n",
    "      the mask that are 0, and will be unchanged for positions that are 1.\n",
    "    num_attention_heads: int. Number of attention heads.\n",
    "    size_per_head: int. Size of each attention head.\n",
    "    query_act: (optional) Activation function for the query transform.\n",
    "    key_act: (optional) Activation function for the key transform.\n",
    "    value_act: (optional) Activation function for the value transform.\n",
    "    attention_probs_dropout_prob: (optional) float. Dropout probability of the\n",
    "      attention probabilities.\n",
    "    initializer_range: float. Range of the weight initializer.\n",
    "    do_return_2d_tensor: bool. If True, the output will be of shape [batch_size\n",
    "      * from_seq_length, num_attention_heads * size_per_head]. If False, the\n",
    "      output will be of shape [batch_size, from_seq_length, num_attention_heads\n",
    "      * size_per_head].\n",
    "    batch_size: (Optional) int. If the input is 2D, this might be the batch size\n",
    "      of the 3D version of the `from_tensor` and `to_tensor`.\n",
    "    from_seq_length: (Optional) If the input is 2D, this might be the seq length\n",
    "      of the 3D version of the `from_tensor`.\n",
    "    to_seq_length: (Optional) If the input is 2D, this might be the seq length\n",
    "      of the 3D version of the `to_tensor`.\n",
    "\n",
    "  Returns:\n",
    "    float Tensor of shape [batch_size, from_seq_length,\n",
    "      num_attention_heads * size_per_head]. (If `do_return_2d_tensor` is\n",
    "      true, this will be of shape [batch_size * from_seq_length,\n",
    "      num_attention_heads * size_per_head]).\n",
    "\n",
    "  Raises:\n",
    "    ValueError: Any of the arguments or tensor shapes are invalid.\n",
    "  \"\"\"\n",
    "\n",
    "  def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n",
    "                           seq_length, width):\n",
    "    output_tensor = tf.reshape(\n",
    "        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n",
    "\n",
    "    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n",
    "    return output_tensor\n",
    "\n",
    "  from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n",
    "  to_shape = get_shape_list(to_tensor, expected_rank=[2, 3])\n",
    "\n",
    "  if len(from_shape) != len(to_shape):\n",
    "    raise ValueError(\n",
    "        \"The rank of `from_tensor` must match the rank of `to_tensor`.\")\n",
    "\n",
    "  if len(from_shape) == 3:\n",
    "    batch_size = from_shape[0]\n",
    "    from_seq_length = from_shape[1]\n",
    "    to_seq_length = to_shape[1]\n",
    "  elif len(from_shape) == 2:\n",
    "    if (batch_size is None or from_seq_length is None or to_seq_length is None):\n",
    "      raise ValueError(\n",
    "          \"When passing in rank 2 tensors to attention_layer, the values \"\n",
    "          \"for `batch_size`, `from_seq_length`, and `to_seq_length` \"\n",
    "          \"must all be specified.\")\n",
    "\n",
    "  # Scalar dimensions referenced here:\n",
    "  #   B = batch size (number of sequences)\n",
    "  #   F = `from_tensor` sequence length\n",
    "  #   T = `to_tensor` sequence length\n",
    "  #   N = `num_attention_heads`\n",
    "  #   H = `size_per_head`\n",
    "\n",
    "  from_tensor_2d = reshape_to_matrix(from_tensor)\n",
    "  to_tensor_2d = reshape_to_matrix(to_tensor)\n",
    "\n",
    "  # `query_layer` = [B*F, N*H]\n",
    "  # query_layer = tf.layers.dense(\n",
    "  #     from_tensor_2d,\n",
    "  #     num_attention_heads * size_per_head,\n",
    "  #     activation=query_act,\n",
    "  #     name=\"query\",\n",
    "  #     kernel_initializer=create_initializer(initializer_range))\n",
    "  \n",
    "  query_layer = tf.keras.layers.Dense(\n",
    "    units=num_attention_heads * size_per_head,\n",
    "    activation=query_act,\n",
    "    kernel_initializer=create_initializer(initializer_range),\n",
    "    name=\"query\"\n",
    "  )(from_tensor_2d)\n",
    "  \n",
    "\n",
    "  # `key_layer` = [B*T, N*H]\n",
    "  # key_layer = tf.layers.dense(\n",
    "  #     to_tensor_2d,\n",
    "  #     num_attention_heads * size_per_head,\n",
    "  #     activation=key_act,\n",
    "  #     name=\"key\",\n",
    "  #     kernel_initializer=create_initializer(initializer_range))\n",
    "\n",
    "  key_layer = tf.keras.layers.Dense(\n",
    "    units=num_attention_heads * size_per_head,\n",
    "    activation=key_act,\n",
    "    kernel_initializer=create_initializer(initializer_range),\n",
    "    name=\"key\"\n",
    "  )(to_tensor_2d)\n",
    "\n",
    "  # `value_layer` = [B*T, N*H]\n",
    "  # value_layer = tf.layers.dense(\n",
    "  #     to_tensor_2d,\n",
    "  #     num_attention_heads * size_per_head,\n",
    "  #     activation=value_act,\n",
    "  #     name=\"value\",\n",
    "  #     kernel_initializer=create_initializer(initializer_range))\n",
    "\n",
    "  value_layer = tf.keras.layers.Dense(\n",
    "    units=num_attention_heads * size_per_head,\n",
    "    activation=value_act,\n",
    "    kernel_initializer=create_initializer(initializer_range),\n",
    "    name=\"value\"\n",
    "    )(to_tensor_2d)\n",
    "\n",
    "  # `query_layer` = [B, N, F, H]\n",
    "  query_layer = transpose_for_scores(query_layer, batch_size,\n",
    "                                     num_attention_heads, from_seq_length,\n",
    "                                     size_per_head)\n",
    "\n",
    "  # `key_layer` = [B, N, T, H]\n",
    "  key_layer = transpose_for_scores(key_layer, batch_size, num_attention_heads,\n",
    "                                   to_seq_length, size_per_head)\n",
    "\n",
    "  # Take the dot product between \"query\" and \"key\" to get the raw\n",
    "  # attention scores.\n",
    "  # `attention_scores` = [B, N, F, T]\n",
    "  attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\n",
    "  attention_scores = tf.multiply(attention_scores,\n",
    "                                 1.0 / math.sqrt(float(size_per_head)))\n",
    "\n",
    "  if attention_mask is not None:\n",
    "    # `attention_mask` = [B, 1, F, T]\n",
    "    attention_mask = tf.expand_dims(attention_mask, axis=[1])\n",
    "\n",
    "    # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n",
    "    # masked positions, this operation will create a tensor which is 0.0 for\n",
    "    # positions we want to attend and -10000.0 for masked positions.\n",
    "    adder = (1.0 - tf.cast(attention_mask, tf.float32)) * -10000.0\n",
    "\n",
    "    # Since we are adding it to the raw scores before the softmax, this is\n",
    "    # effectively the same as removing these entirely.\n",
    "    attention_scores += adder\n",
    "\n",
    "  # Normalize the attention scores to probabilities.\n",
    "  # `attention_probs` = [B, N, F, T]\n",
    "  attention_probs = tf.nn.softmax(attention_scores)\n",
    "\n",
    "  # This is actually dropping out entire tokens to attend to, which might\n",
    "  # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "  attention_probs = dropout(attention_probs, attention_probs_dropout_prob)\n",
    "\n",
    "  # `value_layer` = [B, T, N, H]\n",
    "  value_layer = tf.reshape(\n",
    "      value_layer,\n",
    "      [batch_size, to_seq_length, num_attention_heads, size_per_head])\n",
    "\n",
    "  # `value_layer` = [B, N, T, H]\n",
    "  value_layer = tf.transpose(value_layer, [0, 2, 1, 3])\n",
    "\n",
    "  # `context_layer` = [B, N, F, H]\n",
    "  context_layer = tf.matmul(attention_probs, value_layer)\n",
    "\n",
    "  # `context_layer` = [B, F, N, H]\n",
    "  context_layer = tf.transpose(context_layer, [0, 2, 1, 3])\n",
    "\n",
    "  if do_return_2d_tensor:\n",
    "    # `context_layer` = [B*F, N*H]\n",
    "    context_layer = tf.reshape(\n",
    "        context_layer,\n",
    "        [batch_size * from_seq_length, num_attention_heads * size_per_head])\n",
    "  else:\n",
    "    # `context_layer` = [B, F, N*H]\n",
    "    context_layer = tf.reshape(\n",
    "        context_layer,\n",
    "        [batch_size, from_seq_length, num_attention_heads * size_per_head])\n",
    "\n",
    "  return context_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "3\n",
      "shape [2, 5, 512]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 5 \n",
      "non static index []\n",
      "Index: 2, dimension: 512 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "3\n",
      "shape [2, 5, 512]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 5 \n",
      "non static index []\n",
      "Index: 2, dimension: 512 \n",
      "non static index []\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 512), dtype=float32, numpy=\n",
       "array([[[-0.40333265, -0.3784229 , -0.143223  , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.4267364 , -0.40483668,  0.30990708, ..., -0.3974648 ,\n",
       "          0.76644814,  0.9971383 ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.45778412,\n",
       "          0.31713015,  0.8796923 ],\n",
       "        [ 0.        ,  0.        ,  0.        , ..., -0.3402324 ,\n",
       "          0.8720439 ,  0.7583439 ]],\n",
       "\n",
       "       [[ 0.        ,  0.        ,  0.        , ...,  0.1645975 ,\n",
       "          0.42204377,  1.0416461 ],\n",
       "        [-0.5131816 , -0.43767893,  0.4626186 , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.6869402 , -0.8825668 ,  0.07383692, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.6917478 , -0.46846235, -0.05931417, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Define the input tensors\n",
    "batch_size = 2\n",
    "from_seq_length = 5\n",
    "to_seq_length = 5\n",
    "hidden_size = 512\n",
    "num_attention_heads = 8\n",
    "size_per_head = hidden_size // num_attention_heads\n",
    "\n",
    "from_tensor = tf.random.uniform((batch_size, from_seq_length, hidden_size))\n",
    "to_tensor = tf.random.uniform((batch_size, to_seq_length, hidden_size))\n",
    "attention_mask = tf.ones((batch_size, from_seq_length, to_seq_length))\n",
    "\n",
    "# Call the attention_layer function\n",
    "output = attention_layer(\n",
    "    from_tensor=from_tensor,\n",
    "    to_tensor=to_tensor,\n",
    "    attention_mask=attention_mask,\n",
    "    num_attention_heads=num_attention_heads,\n",
    "    size_per_head=size_per_head,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    initializer_range=0.02,\n",
    "    do_return_2d_tensor=False,\n",
    "    batch_size=batch_size,\n",
    "    from_seq_length=from_seq_length,\n",
    "    to_seq_length=to_seq_length\n",
    ")\n",
    "\n",
    "output\n",
    "\n",
    "# Initialize and run the session\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     sess.run(tf.compat.v1.global_variables_initializer())\n",
    "#     output_val = sess.run(output)\n",
    "#     print(output_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def transformer_model(input_tensor,\n",
    "                      attention_mask=None,\n",
    "                      hidden_size=768,\n",
    "                      num_hidden_layers=12,\n",
    "                      num_attention_heads=12,\n",
    "                      intermediate_size=3072,\n",
    "                      intermediate_act_fn=tf.nn.gelu,\n",
    "                      hidden_dropout_prob=0.1,\n",
    "                      attention_probs_dropout_prob=0.1,\n",
    "                      initializer_range=0.02,\n",
    "                      do_return_all_layers=False):\n",
    "    \"\"\"Multi-headed, multi-layer Transformer from \"Attention is All You Need\".\n",
    "\n",
    "    This is almost an exact implementation of the original Transformer encoder.\n",
    "\n",
    "    See the original paper:\n",
    "    https://arxiv.org/abs/1706.03762\n",
    "\n",
    "    Also see:\n",
    "    https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py\n",
    "\n",
    "    Args:\n",
    "        input_tensor: float Tensor of shape [batch_size, seq_length, hidden_size].\n",
    "        attention_mask: (optional) int32 Tensor of shape [batch_size, seq_length,\n",
    "          seq_length], with 1 for positions that can be attended to and 0 in\n",
    "          positions that should not be.\n",
    "        hidden_size: int. Hidden size of the Transformer.\n",
    "        num_hidden_layers: int. Number of layers (blocks) in the Transformer.\n",
    "        num_attention_heads: int. Number of attention heads in the Transformer.\n",
    "        intermediate_size: int. The size of the \"intermediate\" (a.k.a., feed\n",
    "          forward) layer.\n",
    "        intermediate_act_fn: function. The non-linear activation function to apply\n",
    "          to the output of the intermediate/feed-forward layer.\n",
    "        hidden_dropout_prob: float. Dropout probability for the hidden layers.\n",
    "        attention_probs_dropout_prob: float. Dropout probability of the attention\n",
    "          probabilities.\n",
    "        initializer_range: float. Range of the initializer (stddev of truncated\n",
    "          normal).\n",
    "        do_return_all_layers: Whether to also return all layers or just the final\n",
    "          layer.\n",
    "\n",
    "    Returns:\n",
    "        float Tensor of shape [batch_size, seq_length, hidden_size], the final\n",
    "        hidden layer of the Transformer.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: A Tensor shape or parameter is invalid.\n",
    "    \"\"\"\n",
    "    if hidden_size % num_attention_heads != 0:\n",
    "        raise ValueError(\n",
    "            \"The hidden size (%d) is not a multiple of the number of attention \"\n",
    "            \"heads (%d)\" % (hidden_size, num_attention_heads))\n",
    "\n",
    "    attention_head_size = int(hidden_size / num_attention_heads)\n",
    "    input_shape = get_shape_list(input_tensor, expected_rank=3)\n",
    "    batch_size = input_shape[0]\n",
    "    seq_length = input_shape[1]\n",
    "    input_width = input_shape[2]\n",
    "\n",
    "    if input_width != hidden_size:\n",
    "        raise ValueError(\"The width of the input tensor (%d) != hidden size (%d)\" %\n",
    "                         (input_width, hidden_size))\n",
    "\n",
    "    prev_output = reshape_to_matrix(input_tensor)\n",
    "\n",
    "    all_layer_outputs = []\n",
    "    for layer_idx in range(num_hidden_layers):\n",
    "        with tf.compat.v1.variable_scope(\"layer_%d\" % layer_idx):\n",
    "            layer_input = prev_output\n",
    "\n",
    "            with tf.compat.v1.variable_scope(\"attention\"):\n",
    "                attention_heads = []\n",
    "                with tf.compat.v1.variable_scope(\"self\"):\n",
    "                    attention_head = attention_layer(\n",
    "                        from_tensor=layer_input,\n",
    "                        to_tensor=layer_input,\n",
    "                        attention_mask=attention_mask,\n",
    "                        num_attention_heads=num_attention_heads,\n",
    "                        size_per_head=attention_head_size,\n",
    "                        attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "                        initializer_range=initializer_range,\n",
    "                        do_return_2d_tensor=True,\n",
    "                        batch_size=batch_size,\n",
    "                        from_seq_length=seq_length,\n",
    "                        to_seq_length=seq_length)\n",
    "                    attention_heads.append(attention_head)\n",
    "\n",
    "                attention_output = None\n",
    "                if len(attention_heads) == 1:\n",
    "                    attention_output = attention_heads[0]\n",
    "                else:\n",
    "                    attention_output = tf.concat(attention_heads, axis=-1)\n",
    "\n",
    "                with tf.compat.v1.variable_scope(\"output\"):\n",
    "                    attention_output = tf.keras.layers.Dense(\n",
    "                        units=hidden_size,\n",
    "                        kernel_initializer=create_initializer(initializer_range)\n",
    "                    )(attention_output)\n",
    "                    attention_output = dropout(attention_output, hidden_dropout_prob)\n",
    "                    attention_output = layer_norm(attention_output + layer_input)\n",
    "\n",
    "            with tf.compat.v1.variable_scope(\"intermediate\"):\n",
    "                intermediate_output = tf.keras.layers.Dense(\n",
    "                    units=intermediate_size,\n",
    "                    activation=intermediate_act_fn,\n",
    "                    kernel_initializer=create_initializer(initializer_range)\n",
    "                )(attention_output)\n",
    "\n",
    "            with tf.compat.v1.variable_scope(\"output\"):\n",
    "                layer_output = tf.keras.layers.Dense(\n",
    "                    units=hidden_size,\n",
    "                    kernel_initializer=create_initializer(initializer_range)\n",
    "                )(intermediate_output)\n",
    "                layer_output = dropout(layer_output, hidden_dropout_prob)\n",
    "                layer_output = layer_norm(layer_output + attention_output)\n",
    "                prev_output = layer_output\n",
    "                all_layer_outputs.append(layer_output)\n",
    "\n",
    "    if do_return_all_layers:\n",
    "        final_outputs = []\n",
    "        for layer_output in all_layer_outputs:\n",
    "            final_output = reshape_from_matrix(layer_output, input_shape)\n",
    "            final_outputs.append(final_output)\n",
    "        return final_outputs\n",
    "    else:\n",
    "        final_output = reshape_from_matrix(prev_output, input_shape)\n",
    "        return final_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: True}\n",
      "3\n",
      "shape [2, 5, 768]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 5 \n",
      "non static index []\n",
      "Index: 2, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n",
      "shape [10, 768]\n",
      "Index: 0, dimension: 10 \n",
      "non static index []\n",
      "Index: 1, dimension: 768 \n",
      "non static index []\n"
     ]
    }
   ],
   "source": [
    "# Define the input tensor\n",
    "batch_size = 2\n",
    "seq_length = 5\n",
    "hidden_size = 768\n",
    "\n",
    "input_tensor = tf.random.uniform((batch_size, seq_length, hidden_size))\n",
    "attention_mask = tf.ones((batch_size, seq_length, seq_length))\n",
    "\n",
    "# Call the transformer_model function\n",
    "output = transformer_model(\n",
    "    input_tensor=input_tensor,\n",
    "    attention_mask=attention_mask,\n",
    "    hidden_size=hidden_size,\n",
    "    num_hidden_layers=12,\n",
    "    num_attention_heads=12,\n",
    "    intermediate_size=3072,\n",
    "    intermediate_act_fn=tf.nn.gelu,\n",
    "    hidden_dropout_prob=0.1,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    initializer_range=0.02,\n",
    "    do_return_all_layers=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(activation_string):\n",
    "  \"\"\"Maps a string to a Python function, e.g., \"relu\" => `tf.nn.relu`.\n",
    "\n",
    "  Args:\n",
    "    activation_string: String name of the activation function.\n",
    "\n",
    "  Returns:\n",
    "    A Python function corresponding to the activation function. If\n",
    "    `activation_string` is None, empty, or \"linear\", this will return None.\n",
    "    If `activation_string` is not a string, it will return `activation_string`.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: The `activation_string` does not correspond to a known\n",
    "      activation.\n",
    "  \"\"\"\n",
    "\n",
    "  # We assume that anything that\"s not a string is already an activation\n",
    "  # function, so we just return it.\n",
    "  if not isinstance(activation_string, six.string_types):\n",
    "    return activation_string\n",
    "\n",
    "  if not activation_string:\n",
    "    return None\n",
    "\n",
    "  act = activation_string.lower()\n",
    "  if act == \"linear\":\n",
    "    return None\n",
    "  elif act == \"relu\":\n",
    "    return tf.nn.relu\n",
    "  elif act == \"gelu\":\n",
    "    return gelu\n",
    "  elif act == \"tanh\":\n",
    "    return tf.tanh\n",
    "  else:\n",
    "    raise ValueError(\"Unsupported activation: %s\" % act)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertModel(object):\n",
    "\n",
    "    \"\"\"BERT model (\"Bidirectional Encoder Representations for Transformers\").\n",
    "    \n",
    "    Example usage:\n",
    "        \n",
    "    \n",
    "        ```Python \n",
    "        # Already been converted into WordPiece token ids \n",
    "        input_ids = tf.constant([[31, 51, 99], [15, 5, 0]])\n",
    "        input_mask = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
    "        input_type_ids = tf.constant([[0, 0, 1], [0, 2, 0]])\n",
    "\n",
    "        config = modeling.BertConfig(vocab_size = 32000, hidden_size = 512,\n",
    "        num_hidden_layers=8, num_attention_heads=6, intermediate_size=1024)\n",
    "\n",
    "        model = modeling.BertModel(config=config, is_training = True,\n",
    "        input_ids=input_ids, input_mask=input_mask, token_type_ids=token_type_ids\n",
    "        )\n",
    "\n",
    "        label_embeddings = tf.compat.v1.get_variable(...)\n",
    "        pooled_output = model.get_pooled_output()\n",
    "        logits = tf.matmul(pooled_output, label_embeddings)\n",
    "\n",
    "        ...\n",
    "        ```\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 is_training,\n",
    "                 input_ids,\n",
    "                 input_mask=None,\n",
    "                 token_type_ids=None,\n",
    "                 use_one_hot_embeddings=False,\n",
    "                 scope=None) -> None:\n",
    "        \n",
    "\n",
    "        \"\"\"Constructor for BertModel.\n",
    "        \n",
    "        Args:\n",
    "            config: `BertConfig` instance.\n",
    "            is_training: bool. True for training model, false for eval model. Controls \n",
    "                whether dropout will be applied.\n",
    "\n",
    "            input_ids: int32 Tensor of shape [batch_size, seq_len]\n",
    "            input_mask: (optional) int32 Tensor of shape [batch_size, seq_length]\n",
    "            token_type_ids: (optional) int32 Tensor of shape [batch_size, seq_length]\n",
    "            use_one_hot_embeddings: (Optional) bool. Whether to use one-hot word \n",
    "                embeddings or tf.embedding_lookup() for the word embeddings.\n",
    "\n",
    "            scope: (optional) variable scope. Defaults to \"bert\".\n",
    "\n",
    "        Raises:\n",
    "            ValueError: The config is invalid or one of the input tensor shapes\n",
    "            is invalid.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        config = copy.deepcopy(config)\n",
    "        # print(config)\n",
    "        # print(config.vocab_size)\n",
    "        if not is_training:\n",
    "            config.hidden_dropout_prob = 0.0 \n",
    "            config.attention_probs_dropout_prob = 0.0\n",
    "\n",
    "        input_shape = get_shape_list(input_ids, expected_rank=2)\n",
    "        print(\"input shape\", input_shape)\n",
    "\n",
    "        batch_size = input_shape[0]\n",
    "        seq_length = input_shape[1]\n",
    "        print(f\"Batch size: {batch_size}, sequence length: {seq_length}\")\n",
    "\n",
    "        if input_mask is None:\n",
    "            input_mask = tf.ones(shape=[batch_size, seq_length], dtype=tf.int32)\n",
    "\n",
    "        with tf.compat.v1.variable_scope(scope, default_name=\"bert\"):\n",
    "            with tf.compat.v1.variable_scope(\"embeddings\"):\n",
    "\n",
    "                print(config.vocab_size)\n",
    "\n",
    "                # Perform embedding lookup on the word ids.\n",
    "                (self.embedding_output, self.embedding_table) = embedding_lookup(\n",
    "                    input_ids=input_ids,\n",
    "                    vocab_size=config.vocab_size,\n",
    "                    embedding_size=config.hidden_size,\n",
    "                    initializer_range=config.initializer_range,\n",
    "                    word_embedding_name=\"word_embeddings\",\n",
    "                    use_one_hot_embeddings=use_one_hot_embeddings\n",
    "                )\n",
    "\n",
    "                print(self.embedding_output)\n",
    "                print(self.embedding_table)\n",
    "\n",
    "                # Add positional embeddings and token type embeddings, then layer \n",
    "                # normalize and perform dropout.\n",
    "                \n",
    "                self.embedding_output = embedding_postprocessor(\n",
    "                    input_tensor=self.embedding_output,\n",
    "                    use_token_type=True,\n",
    "                    token_type_ids=token_type_ids,\n",
    "                    token_type_vocab_size=config.type_vocab_size,\n",
    "                    token_type_embedding_name=\"token_type_embeddings\",\n",
    "                    use_positional_embeddings=True,\n",
    "                    position_embedding_name=\"position_embeddings\",\n",
    "                    initializer_range=config.initializer_range,\n",
    "                    max_position_embeddings=config.max_position_embeddings,\n",
    "                    dropout_prob=config.hidden_dropout_prob\n",
    "                )\n",
    "                \n",
    "\n",
    "                print(\"Embedding Output\", self.embedding_output)\n",
    "\n",
    "            with tf.compat.v1.variable_scope(\"encoder\"):\n",
    "\n",
    "                # This converts a 2D mask of shape [batch_size, seq_length] to a 3D \n",
    "                # mask of shape [batch_size, seq_length, seq_length] which is used \n",
    "                # for the attention scores.\n",
    "\n",
    "                attention_mask = create_attention_mask_from_input_mask(\n",
    "                    from_tensor=input_ids,\n",
    "                    to_mask=input_mask\n",
    "                )\n",
    "\n",
    "                print(\"attention_mask\", attention_mask)\n",
    "\n",
    "                # Run the stocked transformer.\n",
    "                # `Sequence_output` shape = [batch_size, seq_length, hidden_size]\n",
    "                \n",
    "                self.all_encoder_layers = transformer_model(\n",
    "                input_tensor=self.embedding_output,\n",
    "                attention_mask=attention_mask,\n",
    "                hidden_size=config.hidden_size,\n",
    "                num_hidden_layers=config.num_hidden_layers,\n",
    "                num_attention_heads=config.num_attention_heads,\n",
    "                intermediate_size=config.intermediate_size,\n",
    "                intermediate_act_fn=get_activation(config.hidden_act),\n",
    "                hidden_dropout_prob=config.hidden_dropout_prob,\n",
    "                attention_probs_dropout_prob=config.attention_probs_dropout_prob,\n",
    "                initializer_range=config.initializer_range,\n",
    "                do_return_all_layers=True)\n",
    "\n",
    "\n",
    "            self.sequence_output = self.all_encoder_layers[-1]\n",
    "\n",
    "            # The \"pooler\" converts the encoded sequence tensor of shape \n",
    "            # [batch_size, seq_length, hidden_size] to a tensor of shape \n",
    "            # [batch_size, hidden_size]. This is neccessary for segment-level \n",
    "            # (or segment-pair-level) classification task where we need a fixed \n",
    "            # dimensional representation of the segment.\n",
    "\n",
    "            with tf.compat.v1.variable_scope(\"pooler\"):\n",
    "\n",
    "                # we \"pool\" the model by simply taking the hidden state corresponding \n",
    "                # to the first token. we assume that this has been pre-trained.\n",
    "\n",
    "                first_token_tensor = tf.squeeze(self.sequence_output[:, 0:1, :], axis=1)\n",
    "                self.pooled_output = tf.keras.layers.Dense(\n",
    "                    units=config.hidden_size,\n",
    "                    activation=tf.tanh,\n",
    "                    kernel_initializer=create_initializer(config.initializer_range)\n",
    "                )(first_token_tensor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_pooled_output(self):\n",
    "        return self.pooled_output\n",
    "    \n",
    "\n",
    "    def get_sequence_output(self):\n",
    "        \"\"\"Gets final hidden layer of encoder.\n",
    "        \n",
    "\n",
    "        Returns:\n",
    "            float Tensor of shape [batch_size, seq_length, hidden_size] corresponding \n",
    "            to the final hidden of the transformer encoder.\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        return self.sequence_output\n",
    "    \n",
    "\n",
    "    def get_all_encoder_layers(self):\n",
    "        return self.all_encoder_layers\n",
    "    \n",
    "\n",
    "    def get_embedding_output(self):\n",
    "\n",
    "        \"\"\"Gets output of the embedding lookup (i.e, input to the transformer.)\n",
    "        \n",
    "        Returns:\n",
    "            float Tensor of shape [batch_sie, seq_length, hidden_size] correspoinding \n",
    "            to the output of the embedding layer, after summing the word \n",
    "            embedding with the positional embeddings and the token type embedings.\n",
    "            the performing layer normalization. This is the input to the transformer.\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        return self.embedding_output\n",
    "    \n",
    "\n",
    "\n",
    "    def get_embedding_table(self):\n",
    "        return self.embedding_table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: True}\n",
      "2\n",
      "shape [2, 3]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n",
      "input shape [2, 3]\n",
      "Batch size: 2, sequence length: 3\n",
      "32000\n",
      "Embedding Table <tf.Variable 'bert_31/embeddings/word_embeddings:0' shape=(32000, 512) dtype=float32, numpy=\n",
      "array([[-0.01579733,  0.01983668,  0.03018808, ...,  0.02285177,\n",
      "         0.00986339, -0.03662904],\n",
      "       [ 0.01129133,  0.02367693,  0.02476444, ...,  0.02539271,\n",
      "        -0.02909178, -0.0046701 ],\n",
      "       [-0.00577935,  0.00406032, -0.00456808, ..., -0.02330289,\n",
      "         0.01173159, -0.01237737],\n",
      "       ...,\n",
      "       [-0.00188866,  0.01739826, -0.00463522, ..., -0.00485624,\n",
      "        -0.01676391, -0.00732287],\n",
      "       [-0.01123592, -0.00453435,  0.00429412, ...,  0.01970119,\n",
      "         0.00169928,  0.02770593],\n",
      "       [-0.00919701,  0.01601604, -0.02127862, ...,  0.00446597,\n",
      "         0.00667019,  0.01778616]], dtype=float32)>\n",
      "Gather output tf.Tensor(\n",
      "[[ 0.00335622 -0.01301751 -0.00733621 ... -0.01665836  0.03256335\n",
      "   0.03713591]\n",
      " [-0.00758367  0.00273899  0.00850531 ...  0.00604169  0.00630968\n",
      "   0.01755826]\n",
      " [ 0.00419988 -0.01619805 -0.00055505 ... -0.01368877  0.02154543\n",
      "   0.00251019]\n",
      " [ 0.00239331 -0.01241438  0.00851254 ...  0.0164944  -0.01468653\n",
      "   0.00140612]\n",
      " [-0.00590932 -0.03248186  0.01479298 ... -0.01911551 -0.01557914\n",
      "   0.02275647]\n",
      " [-0.01579733  0.01983668  0.03018808 ...  0.02285177  0.00986339\n",
      "  -0.03662904]], shape=(6, 512), dtype=float32)\n",
      "shape [2, 3, 1]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n",
      "Index: 2, dimension: 1 \n",
      "non static index []\n",
      "Output: (tf.Tensor(\n",
      "[[[ 0.00335622 -0.01301751 -0.00733621 ... -0.01665836  0.03256335\n",
      "    0.03713591]\n",
      "  [-0.00758367  0.00273899  0.00850531 ...  0.00604169  0.00630968\n",
      "    0.01755826]\n",
      "  [ 0.00419988 -0.01619805 -0.00055505 ... -0.01368877  0.02154543\n",
      "    0.00251019]]\n",
      "\n",
      " [[ 0.00239331 -0.01241438  0.00851254 ...  0.0164944  -0.01468653\n",
      "    0.00140612]\n",
      "  [-0.00590932 -0.03248186  0.01479298 ... -0.01911551 -0.01557914\n",
      "    0.02275647]\n",
      "  [-0.01579733  0.01983668  0.03018808 ...  0.02285177  0.00986339\n",
      "   -0.03662904]]], shape=(2, 3, 512), dtype=float32)) Embedding Table: (<tf.Variable 'bert_31/embeddings/word_embeddings:0' shape=(32000, 512) dtype=float32, numpy=\n",
      "array([[-0.01579733,  0.01983668,  0.03018808, ...,  0.02285177,\n",
      "         0.00986339, -0.03662904],\n",
      "       [ 0.01129133,  0.02367693,  0.02476444, ...,  0.02539271,\n",
      "        -0.02909178, -0.0046701 ],\n",
      "       [-0.00577935,  0.00406032, -0.00456808, ..., -0.02330289,\n",
      "         0.01173159, -0.01237737],\n",
      "       ...,\n",
      "       [-0.00188866,  0.01739826, -0.00463522, ..., -0.00485624,\n",
      "        -0.01676391, -0.00732287],\n",
      "       [-0.01123592, -0.00453435,  0.00429412, ...,  0.01970119,\n",
      "         0.00169928,  0.02770593],\n",
      "       [-0.00919701,  0.01601604, -0.02127862, ...,  0.00446597,\n",
      "         0.00667019,  0.01778616]], dtype=float32)>)\n",
      "tf.Tensor(\n",
      "[[[ 0.00335622 -0.01301751 -0.00733621 ... -0.01665836  0.03256335\n",
      "    0.03713591]\n",
      "  [-0.00758367  0.00273899  0.00850531 ...  0.00604169  0.00630968\n",
      "    0.01755826]\n",
      "  [ 0.00419988 -0.01619805 -0.00055505 ... -0.01368877  0.02154543\n",
      "    0.00251019]]\n",
      "\n",
      " [[ 0.00239331 -0.01241438  0.00851254 ...  0.0164944  -0.01468653\n",
      "    0.00140612]\n",
      "  [-0.00590932 -0.03248186  0.01479298 ... -0.01911551 -0.01557914\n",
      "    0.02275647]\n",
      "  [-0.01579733  0.01983668  0.03018808 ...  0.02285177  0.00986339\n",
      "   -0.03662904]]], shape=(2, 3, 512), dtype=float32)\n",
      "<tf.Variable 'bert_31/embeddings/word_embeddings:0' shape=(32000, 512) dtype=float32, numpy=\n",
      "array([[-0.01579733,  0.01983668,  0.03018808, ...,  0.02285177,\n",
      "         0.00986339, -0.03662904],\n",
      "       [ 0.01129133,  0.02367693,  0.02476444, ...,  0.02539271,\n",
      "        -0.02909178, -0.0046701 ],\n",
      "       [-0.00577935,  0.00406032, -0.00456808, ..., -0.02330289,\n",
      "         0.01173159, -0.01237737],\n",
      "       ...,\n",
      "       [-0.00188866,  0.01739826, -0.00463522, ..., -0.00485624,\n",
      "        -0.01676391, -0.00732287],\n",
      "       [-0.01123592, -0.00453435,  0.00429412, ...,  0.01970119,\n",
      "         0.00169928,  0.02770593],\n",
      "       [-0.00919701,  0.01601604, -0.02127862, ...,  0.00446597,\n",
      "         0.00667019,  0.01778616]], dtype=float32)>\n",
      "{3: True}\n",
      "3\n",
      "shape [2, 3, 512]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n",
      "Index: 2, dimension: 512 \n",
      "non static index []\n",
      "Embedding Output None\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [2, 3]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n",
      "{2: True}\n",
      "2\n",
      "shape [2, 3]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n",
      "attention_mask tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(2, 3, 3), dtype=float32)\n",
      "{3: True}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[242], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m token_type_ids \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant([[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m]])\n\u001b[0;32m      6\u001b[0m config \u001b[38;5;241m=\u001b[39m BertConfig(vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32000\u001b[39m, hidden_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, num_hidden_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, num_attention_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, intermediate_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBertModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[241], line 131\u001b[0m, in \u001b[0;36mBertModel.__init__\u001b[1;34m(self, config, is_training, input_ids, input_mask, token_type_ids, use_one_hot_embeddings, scope)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, attention_mask)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# Run the stocked transformer.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# `Sequence_output` shape = [batch_size, seq_length, hidden_size]\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_encoder_layers \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_hidden_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_hidden_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_attention_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_attention_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_activation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_act\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dropout_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_dropout_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_probs_dropout_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_probs_dropout_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitializer_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_return_all_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_encoder_layers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# The \"pooler\" converts the encoded sequence tensor of shape \u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# [batch_size, seq_length, hidden_size] to a tensor of shape \u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# [batch_size, hidden_size]. This is neccessary for segment-level \u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# (or segment-pair-level) classification task where we need a fixed \u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# dimensional representation of the segment.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[238], line 57\u001b[0m, in \u001b[0;36mtransformer_model\u001b[1;34m(input_tensor, attention_mask, hidden_size, num_hidden_layers, num_attention_heads, intermediate_size, intermediate_act_fn, hidden_dropout_prob, attention_probs_dropout_prob, initializer_range, do_return_all_layers)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe hidden size (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) is not a multiple of the number of attention \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheads (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (hidden_size, num_attention_heads))\n\u001b[0;32m     56\u001b[0m attention_head_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(hidden_size \u001b[38;5;241m/\u001b[39m num_attention_heads)\n\u001b[1;32m---> 57\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[43mget_shape_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m input_shape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     59\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m input_shape[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[192], line 24\u001b[0m, in \u001b[0;36mget_shape_list\u001b[1;34m(tensor, expected_rank, name)\u001b[0m\n\u001b[0;32m     21\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expected_rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[43massert_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexpected_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m shape \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mas_list()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, shape)\n",
      "Cell \u001b[1;32mIn[215], line 30\u001b[0m, in \u001b[0;36massert_rank\u001b[1;34m(tensor, expected_rank, name)\u001b[0m\n\u001b[0;32m     26\u001b[0m         expected_rank_dict[x] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28mprint\u001b[39m(expected_rank_dict)\n\u001b[1;32m---> 30\u001b[0m actual_rank \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241m.\u001b[39mndims\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(actual_rank) \n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actual_rank \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m expected_rank_dict:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# print(\"not found\")\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_ids = tf.constant([[31, 51, 99], [15, 5, 0]])\n",
    "input_mask = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
    "token_type_ids = tf.constant([[0, 0, 1], [0, 2, 0]])\n",
    "\n",
    "config = BertConfig(vocab_size=32000, hidden_size=512, num_hidden_layers=8, num_attention_heads=8, intermediate_size=1024)\n",
    "model = BertModel(config=config, is_training=True, input_ids=input_ids, input_mask=input_mask, token_type_ids=token_type_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: True}\n",
      "2\n",
      "shape [2, 3]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n",
      "input shape [2, 3]\n",
      "Batch size: 2, sequence length: 3\n",
      "32000\n",
      "Embedding Table <tf.Variable 'bert_32/embeddings/word_embeddings:0' shape=(32000, 768) dtype=float32, numpy=\n",
      "array([[ 0.00806402,  0.03579189, -0.01870375, ...,  0.02477551,\n",
      "        -0.01483447,  0.02516099],\n",
      "       [ 0.00455714, -0.00775797,  0.00314786, ...,  0.01359521,\n",
      "        -0.02915041, -0.00601669],\n",
      "       [-0.01729929, -0.00657415,  0.02021743, ..., -0.0106357 ,\n",
      "         0.03546514,  0.029918  ],\n",
      "       ...,\n",
      "       [-0.00526301, -0.01763697, -0.00719418, ..., -0.00426794,\n",
      "        -0.03686734,  0.00103301],\n",
      "       [-0.00753513, -0.0174603 , -0.03416986, ..., -0.01516029,\n",
      "         0.00582749, -0.00478041],\n",
      "       [-0.01279695, -0.02110921,  0.01817811, ...,  0.01213729,\n",
      "        -0.00549091, -0.01491237]], dtype=float32)>\n",
      "Gather output tf.Tensor(\n",
      "[[ 0.00488104  0.03222981  0.01059155 ... -0.00955735  0.00678264\n",
      "  -0.03297691]\n",
      " [-0.00294964 -0.03166464  0.02487179 ...  0.00580575  0.00652544\n",
      "  -0.01807117]\n",
      " [-0.01930359  0.00584707  0.01349476 ...  0.01275831  0.00938716\n",
      "   0.01935669]\n",
      " [-0.00876134  0.02293938 -0.00060103 ... -0.00289186 -0.00084549\n",
      "  -0.01984669]\n",
      " [-0.02823578 -0.00287055 -0.00108829 ... -0.02292289  0.02964157\n",
      "  -0.01980589]\n",
      " [ 0.00806402  0.03579189 -0.01870375 ...  0.02477551 -0.01483447\n",
      "   0.02516099]], shape=(6, 768), dtype=float32)\n",
      "shape [2, 3, 1]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n",
      "Index: 2, dimension: 1 \n",
      "non static index []\n",
      "Output: (tf.Tensor(\n",
      "[[[ 0.00488104  0.03222981  0.01059155 ... -0.00955735  0.00678264\n",
      "   -0.03297691]\n",
      "  [-0.00294964 -0.03166464  0.02487179 ...  0.00580575  0.00652544\n",
      "   -0.01807117]\n",
      "  [-0.01930359  0.00584707  0.01349476 ...  0.01275831  0.00938716\n",
      "    0.01935669]]\n",
      "\n",
      " [[-0.00876134  0.02293938 -0.00060103 ... -0.00289186 -0.00084549\n",
      "   -0.01984669]\n",
      "  [-0.02823578 -0.00287055 -0.00108829 ... -0.02292289  0.02964157\n",
      "   -0.01980589]\n",
      "  [ 0.00806402  0.03579189 -0.01870375 ...  0.02477551 -0.01483447\n",
      "    0.02516099]]], shape=(2, 3, 768), dtype=float32)) Embedding Table: (<tf.Variable 'bert_32/embeddings/word_embeddings:0' shape=(32000, 768) dtype=float32, numpy=\n",
      "array([[ 0.00806402,  0.03579189, -0.01870375, ...,  0.02477551,\n",
      "        -0.01483447,  0.02516099],\n",
      "       [ 0.00455714, -0.00775797,  0.00314786, ...,  0.01359521,\n",
      "        -0.02915041, -0.00601669],\n",
      "       [-0.01729929, -0.00657415,  0.02021743, ..., -0.0106357 ,\n",
      "         0.03546514,  0.029918  ],\n",
      "       ...,\n",
      "       [-0.00526301, -0.01763697, -0.00719418, ..., -0.00426794,\n",
      "        -0.03686734,  0.00103301],\n",
      "       [-0.00753513, -0.0174603 , -0.03416986, ..., -0.01516029,\n",
      "         0.00582749, -0.00478041],\n",
      "       [-0.01279695, -0.02110921,  0.01817811, ...,  0.01213729,\n",
      "        -0.00549091, -0.01491237]], dtype=float32)>)\n",
      "tf.Tensor(\n",
      "[[[ 0.00488104  0.03222981  0.01059155 ... -0.00955735  0.00678264\n",
      "   -0.03297691]\n",
      "  [-0.00294964 -0.03166464  0.02487179 ...  0.00580575  0.00652544\n",
      "   -0.01807117]\n",
      "  [-0.01930359  0.00584707  0.01349476 ...  0.01275831  0.00938716\n",
      "    0.01935669]]\n",
      "\n",
      " [[-0.00876134  0.02293938 -0.00060103 ... -0.00289186 -0.00084549\n",
      "   -0.01984669]\n",
      "  [-0.02823578 -0.00287055 -0.00108829 ... -0.02292289  0.02964157\n",
      "   -0.01980589]\n",
      "  [ 0.00806402  0.03579189 -0.01870375 ...  0.02477551 -0.01483447\n",
      "    0.02516099]]], shape=(2, 3, 768), dtype=float32)\n",
      "<tf.Variable 'bert_32/embeddings/word_embeddings:0' shape=(32000, 768) dtype=float32, numpy=\n",
      "array([[ 0.00806402,  0.03579189, -0.01870375, ...,  0.02477551,\n",
      "        -0.01483447,  0.02516099],\n",
      "       [ 0.00455714, -0.00775797,  0.00314786, ...,  0.01359521,\n",
      "        -0.02915041, -0.00601669],\n",
      "       [-0.01729929, -0.00657415,  0.02021743, ..., -0.0106357 ,\n",
      "         0.03546514,  0.029918  ],\n",
      "       ...,\n",
      "       [-0.00526301, -0.01763697, -0.00719418, ..., -0.00426794,\n",
      "        -0.03686734,  0.00103301],\n",
      "       [-0.00753513, -0.0174603 , -0.03416986, ..., -0.01516029,\n",
      "         0.00582749, -0.00478041],\n",
      "       [-0.01279695, -0.02110921,  0.01817811, ...,  0.01213729,\n",
      "        -0.00549091, -0.01491237]], dtype=float32)>\n",
      "{3: True}\n",
      "3\n",
      "shape [2, 3, 768]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n",
      "Index: 2, dimension: 768 \n",
      "non static index []\n",
      "Embedding Output None\n",
      "2\n",
      "{2: True}\n",
      "3\n",
      "{2: True, 3: True}\n",
      "2\n",
      "shape [2, 3]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n",
      "{2: True}\n",
      "2\n",
      "shape [2, 3]\n",
      "Index: 0, dimension: 2 \n",
      "non static index []\n",
      "Index: 1, dimension: 3 \n",
      "non static index []\n",
      "attention_mask tf.Tensor(\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]], shape=(2, 3, 3), dtype=float32)\n",
      "{3: True}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[243], line 19\u001b[0m\n\u001b[0;32m      6\u001b[0m config_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m32000\u001b[39m,\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m768\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minitializer_range\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.02\u001b[39m\n\u001b[0;32m     15\u001b[0m }\n\u001b[0;32m     17\u001b[0m config \u001b[38;5;241m=\u001b[39m BertConfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[1;32m---> 19\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mBertModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mis_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                  \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                  \u001b[49m\u001b[43minput_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[241], line 131\u001b[0m, in \u001b[0;36mBertModel.__init__\u001b[1;34m(self, config, is_training, input_ids, input_mask, token_type_ids, use_one_hot_embeddings, scope)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m, attention_mask)\n\u001b[0;32m    128\u001b[0m     \u001b[38;5;66;03m# Run the stocked transformer.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;66;03m# `Sequence_output` shape = [batch_size, seq_length, hidden_size]\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_encoder_layers \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_hidden_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_hidden_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_attention_heads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_attention_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mintermediate_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintermediate_act_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_activation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_act\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_dropout_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_dropout_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_probs_dropout_prob\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_probs_dropout_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitializer_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_return_all_layers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_encoder_layers[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# The \"pooler\" converts the encoded sequence tensor of shape \u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# [batch_size, seq_length, hidden_size] to a tensor of shape \u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# [batch_size, hidden_size]. This is neccessary for segment-level \u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# (or segment-pair-level) classification task where we need a fixed \u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# dimensional representation of the segment.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[238], line 57\u001b[0m, in \u001b[0;36mtransformer_model\u001b[1;34m(input_tensor, attention_mask, hidden_size, num_hidden_layers, num_attention_heads, intermediate_size, intermediate_act_fn, hidden_dropout_prob, attention_probs_dropout_prob, initializer_range, do_return_all_layers)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe hidden size (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) is not a multiple of the number of attention \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheads (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (hidden_size, num_attention_heads))\n\u001b[0;32m     56\u001b[0m attention_head_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(hidden_size \u001b[38;5;241m/\u001b[39m num_attention_heads)\n\u001b[1;32m---> 57\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[43mget_shape_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m input_shape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     59\u001b[0m seq_length \u001b[38;5;241m=\u001b[39m input_shape[\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[1;32mIn[192], line 24\u001b[0m, in \u001b[0;36mget_shape_list\u001b[1;34m(tensor, expected_rank, name)\u001b[0m\n\u001b[0;32m     21\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expected_rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 24\u001b[0m     \u001b[43massert_rank\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexpected_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m shape \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mas_list()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m, shape)\n",
      "Cell \u001b[1;32mIn[215], line 30\u001b[0m, in \u001b[0;36massert_rank\u001b[1;34m(tensor, expected_rank, name)\u001b[0m\n\u001b[0;32m     26\u001b[0m         expected_rank_dict[x] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28mprint\u001b[39m(expected_rank_dict)\n\u001b[1;32m---> 30\u001b[0m actual_rank \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[38;5;241m.\u001b[39mndims\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(actual_rank) \n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m actual_rank \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m expected_rank_dict:\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# print(\"not found\")\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_ids = tf.constant([[31, 51, 99], [15, 5, 0]])\n",
    "input_mask = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
    "token_type_ids = tf.constant([[0, 0, 1], [0, 2, 0]])\n",
    "\n",
    "config_dict = {\n",
    "    'vocab_size': 32000,\n",
    "    'hidden_size': 768,\n",
    "    'num_hidden_layers': 12,\n",
    "    'num_attention_heads': 12,\n",
    "    'intermediate_size': 1024,\n",
    "    'hidden_dropout_prob': 0.1,\n",
    "    'attention_probs_dropout_prob': 0.1,\n",
    "    'initializer_range': 0.02\n",
    "}\n",
    "\n",
    "config = BertConfig(**config_dict)\n",
    "\n",
    "model = BertModel(config=config,\n",
    "                  is_training=True,\n",
    "                  input_ids=input_ids,\n",
    "                  input_mask=input_mask,\n",
    "                  token_type_ids=token_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of dense layer:\n",
      " [[0. 0.]\n",
      " [0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Define a simple input tensor\n",
    "input_tensor = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "\n",
    "# Create a dense layer with 2 units and ReLU activation\n",
    "dense_layer = tf.keras.layers.Dense(\n",
    "    units=2,\n",
    "    activation=tf.nn.relu,\n",
    "    kernel_initializer=tf.keras.initializers.GlorotUniform()\n",
    ")\n",
    "\n",
    "# Apply the dense layer to the input tensor\n",
    "output = dense_layer(input_tensor)\n",
    "\n",
    "print(\"Output of dense layer:\\n\", output.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
